{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f159e-cad8-4604-ad71-1e8c6cd1e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d26a081-72cc-4eda-8423-03819f1658b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  unzip zip\n",
      "0 upgraded, 2 newly installed, 0 to remove and 90 not upgraded.\n",
      "Need to get 350 kB of archives.\n",
      "After this operation, 930 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 unzip amd64 6.0-26ubuntu3.2 [175 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 zip amd64 3.0-12build2 [176 kB]\n",
      "Fetched 350 kB in 1s (252 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package unzip.\n",
      "(Reading database ... 21580 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-26ubuntu3.2_amd64.deb ...\n",
      "Unpacking unzip (6.0-26ubuntu3.2) ...\n",
      "Selecting previously unselected package zip.\n",
      "Preparing to unpack .../zip_3.0-12build2_amd64.deb ...\n",
      "Unpacking zip (3.0-12build2) ...\n",
      "Setting up unzip (6.0-26ubuntu3.2) ...\n",
      "Setting up zip (3.0-12build2) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install zip unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f34bbbc-d05f-4134-8c49-1864773ab455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-09 08:04:18--  https://github.com/protocolbuffers/protobuf/releases/download/v3.20.3/protoc-3.20.3-linux-x86_64.zip\n",
      "Resolving github.com (github.com)... 20.27.177.113\n",
      "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
      "302 Foundest sent, awaiting response... \n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/23357588/f23d6b1b-e444-4b7b-8e5f-da7ca0cfa2de?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250209T080418Z&X-Amz-Expires=300&X-Amz-Signature=094a0308cd89f14f8cb6825da5b217d37744ccd167bfb13c5d5586713daf9a50&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dprotoc-3.20.3-linux-x86_64.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-02-09 08:04:19--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/23357588/f23d6b1b-e444-4b7b-8e5f-da7ca0cfa2de?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250209%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250209T080418Z&X-Amz-Expires=300&X-Amz-Signature=094a0308cd89f14f8cb6825da5b217d37744ccd167bfb13c5d5586713daf9a50&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dprotoc-3.20.3-linux-x86_64.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 1713886 (1.6M) [application/octet-stream]\n",
      "Saving to: ‘protoc-3.20.3-linux-x86_64.zip’\n",
      "\n",
      "protoc-3.20.3-linux 100%[===================>]   1.63M  --.-KB/s    in 0.03s   \n",
      "\n",
      "2025-02-09 08:04:19 (52.7 MB/s) - ‘protoc-3.20.3-linux-x86_64.zip’ saved [1713886/1713886]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/protocolbuffers/protobuf/releases/download/v3.20.3/protoc-3.20.3-linux-x86_64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "293da99f-f469-43e0-87e2-0f0ac0a5a5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  protoc-3.20.3-linux-x86_64.zip\n",
      "   creating: protoc3/include/\n",
      "   creating: protoc3/include/google/\n",
      "   creating: protoc3/include/google/protobuf/\n",
      "  inflating: protoc3/include/google/protobuf/empty.proto  \n",
      "  inflating: protoc3/include/google/protobuf/duration.proto  \n",
      "  inflating: protoc3/include/google/protobuf/descriptor.proto  \n",
      "  inflating: protoc3/include/google/protobuf/source_context.proto  \n",
      "  inflating: protoc3/include/google/protobuf/field_mask.proto  \n",
      "   creating: protoc3/include/google/protobuf/compiler/\n",
      "  inflating: protoc3/include/google/protobuf/compiler/plugin.proto  \n",
      "  inflating: protoc3/include/google/protobuf/any.proto  \n",
      "  inflating: protoc3/include/google/protobuf/api.proto  \n",
      "  inflating: protoc3/include/google/protobuf/timestamp.proto  \n",
      "  inflating: protoc3/include/google/protobuf/struct.proto  \n",
      "  inflating: protoc3/include/google/protobuf/type.proto  \n",
      "  inflating: protoc3/include/google/protobuf/wrappers.proto  \n",
      "   creating: protoc3/bin/\n",
      "  inflating: protoc3/bin/protoc      \n",
      "  inflating: protoc3/readme.txt      \n"
     ]
    }
   ],
   "source": [
    "!unzip protoc-3.20.3-linux-x86_64.zip -d protoc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6dd0fab-c423-4549-a603-f6b19ce5d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo mv protoc3/bin/protoc /usr/local/bin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345635e2-f5db-4ba9-93a4-7b8ef19d6535",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo mv protoc3/include/* /usr/local/include/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c5d016-a640-4d08-80c7-909dab976cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libprotoc 3.20.3\n"
     ]
    }
   ],
   "source": [
    "!protoc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "275838e0-45c9-4ff1-b025-eb502618f605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.65.0)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence_transformers)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (10.0.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.9/275.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.1/464.1 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: tzdata, threadpoolctl, scipy, safetensors, regex, protobuf, joblib, scikit-learn, pandas, huggingface-hub, tokenizers, transformers, sentence_transformers\n",
      "Successfully installed huggingface-hub-0.28.1 joblib-1.4.2 pandas-2.2.3 protobuf-5.29.3 regex-2024.11.6 safetensors-0.5.2 scikit-learn-1.6.1 scipy-1.15.1 sentence_transformers-3.4.1 threadpoolctl-3.5.0 tokenizers-0.21.0 transformers-4.48.3 tzdata-2025.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence_transformers pandas transformers protobuf torch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "792e2ec6-c69e-42c2-a916-6ecb507fa817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "981345da-9057-48d9-bdf8-3fb23369eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, XLMRobertaTokenizerFast\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from transformers import XLMRobertaTokenizerFast\n",
    "import sys\n",
    "\n",
    "from sentencepiece import sentencepiece_model_pb2 as pb2_model\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dec674e-ffad-49ef-9e32-3f04a2b46517",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_model_dir = 'short_model'\n",
    "\n",
    "import os\n",
    "\n",
    "os.makedirs(short_model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ba3af7-8d13-418f-8c3e-d13917d141ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8d278f00e24a23b3da40e3210b2e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717ea0281708476fba6b973a2283e2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4c39b662f24b3ca762d6db308f84ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79557961dfaa4520b6df7b415a91a7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = 'BAAI/bge-m3'\n",
    "vocab_orig_path = \"bge-m3-vocab\"\n",
    "vocab_short_path = f\"{short_model_dir}/spiece-short.model\"\n",
    "\n",
    "\n",
    "base_tokenizer = XLMRobertaTokenizerFast.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d9012b-dd94-4602-bf75-3d338219721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = pd.read_csv('corpus.en', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "df_az = pd.read_csv('corpus.az', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "df_en.columns = ['text']\n",
    "df_az.columns = ['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a6217d5-5a3b-414d-beaa-6579205b31d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f77cd2c9084eb49a21f7340959baa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48a7d65899b44b68debb60c0429ad21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt_az = Counter()\n",
    "for text in tqdm(df_az.text):\n",
    "    cnt_az.update(base_tokenizer(text)['input_ids'])\n",
    "    \n",
    "cnt_en = Counter()\n",
    "for text in tqdm(df_en.text):\n",
    "    cnt_en.update(base_tokenizer(text)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1195953-b204-4c41-8736-1c6a5bcadee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37367\n"
     ]
    }
   ],
   "source": [
    "resulting_vocab = {\n",
    "    base_tokenizer.vocab[k] for k in base_tokenizer.special_tokens_map.values()\n",
    "}\n",
    "for k, v in cnt_az.items():\n",
    "    if v >= 3 or k <= 100:\n",
    "        resulting_vocab.add(k)      \n",
    "for k, v in cnt_en.items():\n",
    "    if v >= 10 or k <= 100:\n",
    "        resulting_vocab.add(k)\n",
    "\n",
    "resulting_vocab = sorted(resulting_vocab)\n",
    "print(len(resulting_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ea972c-49d6-4dbb-8115-43e49b7dad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_voc = {idx: word for word, idx in base_tokenizer.vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feb2d047-245c-42fb-8046-3048676447d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.txt', 'w', encoding='utf-8') as f:\n",
    "    for idx in resulting_vocab:\n",
    "        f.write(inv_voc[idx] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae8a11f-8ccb-4983-8e9b-190ccaa51c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af283e0adc9a45b3ab5653cc9484f624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f92e056ecd6482aa8b7f88ec017aa4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7145771cbfe34d17aa9a152cbf647904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('bge-m3-vocab/tokenizer_config.json',\n",
       " 'bge-m3-vocab/special_tokens_map.json',\n",
       " 'bge-m3-vocab/sentencepiece.bpe.model',\n",
       " 'bge-m3-vocab/added_tokens.json',\n",
       " 'bge-m3-vocab/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_orig = AutoModel.from_pretrained(base_model)\n",
    "tokenizer_orig = XLMRobertaTokenizerFast.from_pretrained(base_model)\n",
    "tokenizer_orig.save_pretrained(vocab_orig_path)\n",
    "\n",
    "with open(vocab_orig_path + '/sentencepiece.bpe.model', 'rb') as f:\n",
    "    data = f.read()\n",
    "m = pb2_model.ModelProto()\n",
    "m.ParseFromString(data)\n",
    "\n",
    "for i in range(250000, 0, -1):\n",
    "    if i not in resulting_vocab:\n",
    "        _ = m.pieces.pop(i - 1)\n",
    "    \n",
    "with open(vocab_short_path, 'wb') as f: f.write(m.SerializeToString())\n",
    "m = None\n",
    "\n",
    "tokenizer_fast_tiny = XLMRobertaTokenizerFast(vocab_file=vocab_short_path)\n",
    "tokenizer_fast_tiny.save_pretrained(vocab_orig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c571974-3222-4915-82f0-984f174866c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37367"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer = XLMRobertaTokenizerFast.from_pretrained(vocab_orig_path)\n",
    "new_size = len(new_tokenizer)\n",
    "new_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2b5e4e9-1102-406a-9df7-d6232dcf5ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name BAAI/bge-m3_en_az. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "e = torch.nn.modules.sparse.Embedding(\n",
    "    num_embeddings=len(resulting_vocab),\n",
    "    embedding_dim=1024,\n",
    "    padding_idx=0,\n",
    "    _weight=model_orig.embeddings.word_embeddings.weight.data[resulting_vocab, :]\n",
    ")\n",
    "\n",
    "small_model = AutoModel.from_pretrained(base_model)\n",
    "small_model.config.vocab_size = new_size\n",
    "small_model.set_input_embeddings(e)\n",
    "small_model.tie_weights()\n",
    "\n",
    "### \n",
    "\n",
    "new_tokenizer.model_max_length = 8192\n",
    "\n",
    "small_model.save_pretrained(base_model + '_en_az')\n",
    "new_tokenizer.save_pretrained(base_model + '_en_az')\n",
    "\n",
    "m = SentenceTransformer(base_model + '_en_az')\n",
    "m.save(base_model + '_en_az')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35bb5d1b-e276-464e-87e0-2c8293654f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "model = AutoModel.from_pretrained(\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7537a142-c6f5-4f2d-9ede-5af2108b5bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3_en_az/\")\n",
    "small_model = AutoModel.from_pretrained(\"BAAI/bge-m3_en_az/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f9a48f7-4533-4163-ac0a-7f8b8ca98f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(sentences, model, tokenizer):\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        embeddings = model_output.pooler_output\n",
    "        embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a448617c-4013-4c00-b4aa-0922d33f5411",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['Anam, yüksək ideallar onu ruhlandırır', 'My uncle, high ideals inspire him']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d885f088-382d-48d9-84cf-97a3954c5147",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_new = embed(texts, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c1786a8-df35-494e-8eb8-da9012257f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_old = embed(texts, small_model, small_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61b41d17-3b05-4d3e-80ff-7f9c5989b53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7611496\n",
      "0.7611496\n"
     ]
    }
   ],
   "source": [
    "print(e_new[0].dot(e_new[1]))\n",
    "print(e_old[0].dot(e_old[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08a7c97b-0490-40e8-ad04-53b9f4c41787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17646853783322167\n",
      "0.6164924393270423\n"
     ]
    }
   ],
   "source": [
    "def msize(m):\n",
    "    return sum(p.numel() for p in m.parameters())\n",
    "\n",
    "def get_sizes(model):\n",
    "    model_size = msize(model)\n",
    "    embeddings_size = msize(model.embeddings)\n",
    "    \n",
    "    return model_size, embeddings_size\n",
    "\n",
    "big_model_size, big_embeddings_size = get_sizes(model)\n",
    "small_model_size, small_embeddings_size = get_sizes(small_model)\n",
    "\n",
    "print(small_embeddings_size / big_embeddings_size)\n",
    "print(small_model_size / big_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa2e84-3559-4dd7-a28f-80a2c8dc1375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
